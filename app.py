import streamlit as st
import tempfile
import cv2
import numpy as np
import mediapipe as mp
from PIL import ImageFont, ImageDraw, Image
import joblib
import time

# --- 1. –ó–ê–ì–†–£–ó–ö–ê –†–ï–°–£–†–°–û–í ---

# --- –ü–£–¢–¨ –ö –®–†–ò–§–¢–£ ---
FONT_PATH = 'VERDANA.TTF'
try:
    font_trick = ImageFont.truetype(FONT_PATH, 36)
    font_score = ImageFont.truetype(FONT_PATH, 30)
    font_timer = ImageFont.truetype(FONT_PATH, 96)
except IOError:
    try:
        FONT_PATH = 'C:/Windows/Fonts/Verdana.ttf'
        font_trick = ImageFont.truetype(FONT_PATH, 36)
        font_score = ImageFont.truetype(FONT_PATH, 30)
        font_timer = ImageFont.truetype(FONT_PATH, 96)
    except IOError:
        st.error(f"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —à—Ä–∏—Ñ—Ç '{FONT_PATH}'.")
        st.stop()

# --- –ó–ê–ì–†–£–ó–ö–ê "–ú–û–ó–ì–ê" (–ò–ò-–ú–û–î–ï–õ–ò) ---
try:
    model = joblib.load('gymnastics_model.pkl')
except FileNotFoundError:
    st.error("–û–®–ò–ë–ö–ê: –§–∞–π–ª 'gymnastics_model.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    st.stop()

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe ---
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# --- –°–ª–æ–≤–∞—Ä—å –æ—á–∫–æ–≤ –∏ –Ω–∞–∑–≤–∞–Ω–∏–π ---
SCORES = {"arabesque": 8, "leg_lift": 5, "split": 10, "other": 0}
POSE_NAMES_RU = {"arabesque": "–õ–ê–°–¢–û–ß–ö–ê", "leg_lift": "–ü–û–î–™–ï–ú –ù–û–ì–ò", "split": "–®–ü–ê–ì–ê–¢", "other": "–î–†–£–ì–û–ï"}
# –°–ø–∏—Å–æ–∫ –ø–æ–∑ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
POSE_OPTIONS = list(POSE_NAMES_RU.keys()) # ['arabesque', 'leg_lift', 'split', 'other']

def format_time_manual(timestamp):
    return time.strftime('%H:%M:%S', time.localtime(timestamp))

def format_time(milliseconds):
    if milliseconds < 0: milliseconds = 0
    total_seconds = int(milliseconds / 1000)
    minutes = total_seconds // 60
    seconds = total_seconds % 60
    return f"{minutes:02d}:{seconds:02d}"

# --- 2. –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ì–û (–ò–ò) –ê–ù–ê–õ–ò–ó–ê –§–ê–ô–õ–ê ---
# (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
def process_video_ai(video_bytes, settings):
    # ... (–≤–µ—Å—å –∫–æ–¥ process_video_ai –∏–∑ –≤–µ—Ä—Å–∏–∏ 4.2 –æ—Å—Ç–∞–µ—Ç—Å—è –∑–¥–µ—Å—å) ...
    COOLDOWN_FRAMES = settings["cooldown_frames"]
    FEET_ON_GROUND_THRESHOLD = 0.9
    frames_since_last_score = COOLDOWN_FRAMES
    total_score = 0; protocol_entries = []
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4'); tfile.write(video_bytes); video_path = tfile.name
    cap = cv2.VideoCapture(video_path); total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)); current_frame = 0
    progress_text = st.empty(); progress_bar = st.progress(0); st_frame = st.empty()
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read();
            if not ret: break
            frames_since_last_score += 1; current_frame += 1
            if total_frames > 0: progress_percent = int((current_frame / total_frames) * 100)
            else: progress_percent = 0
            progress_text.text(f"–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ò–ò... –ö–∞–¥—Ä {current_frame}/{total_frames} ({progress_percent}%)"); progress_bar.progress(progress_percent)
            current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC); current_time_str = format_time(current_time_msec)
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB); image.flags.writeable = False
            results = pose.process(image); image.flags.writeable = True; image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            trick_text = ""; current_pose = "other"; both_feet_on_ground = False
            try:
                landmarks = results.pose_landmarks.landmark; pose_landmarks_list = []
                for landmark in landmarks: pose_landmarks_list.extend([landmark.x, landmark.y, landmark.z])
                prediction = model.predict([pose_landmarks_list]); current_pose = prediction[0]
                left_ankle_y = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y; right_ankle_y = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y
                if left_ankle_y > FEET_ON_GROUND_THRESHOLD and right_ankle_y > FEET_ON_GROUND_THRESHOLD: both_feet_on_ground = True
                if current_pose != "other" and not both_feet_on_ground:
                    if frames_since_last_score > COOLDOWN_FRAMES:
                        score = SCORES[current_pose]; label = POSE_NAMES_RU[current_pose]; total_score += score
                        trick_text = f"{label}! +{score} –ë–ê–õ–õ–û–í"; protocol_entries.append(f"{current_time_str} - {label} (+{score}–±)"); frames_since_last_score = 0
            except Exception as e: pass
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); draw = ImageDraw.Draw(pil_image)
            if trick_text: draw.text((50, 50), trick_text, font=font_trick, fill=(0, 255, 0))
            draw.text((50, 100), f"–í–†–ï–ú–Ø: {current_time_str} | –ò–¢–û–ì–û –ë–ê–õ–õ–û–í: {total_score}", font=font_score, fill=(255, 255, 0))
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR); st_frame.image(image, channels="BGR", use_container_width=True)
        cap.release(); progress_text.empty(); progress_bar.empty()
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ò–ò –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {total_score} –±–∞–ª–ª–æ–≤."); st.balloons()
        return total_score, protocol_entries

# --- 3. –§–£–ù–ö–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê –û–î–ù–û–ì–û –°–ù–ò–ú–ö–ê (–ö–ê–î–†–ê) ---
# (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
def analyze_snapshot(frame):
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB); image.flags.writeable = False
    results = None
    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose: results = pose.process(image)
    image.flags.writeable = True; image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    predicted_pose = "other"; score = 0; label = POSE_NAMES_RU["other"]
    try:
        if results and results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark; pose_landmarks_list = []
            for landmark in landmarks: pose_landmarks_list.extend([landmark.x, landmark.y, landmark.z])
            prediction = model.predict([pose_landmarks_list]); predicted_pose = prediction[0]
            score = SCORES[predicted_pose]; label = POSE_NAMES_RU[predicted_pose]
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        else: st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø–æ–∑—É –Ω–∞ —Å–Ω–∏–º–∫–µ.")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–Ω–∏–º–∫–∞: {e}"); predicted_pose = "error"; label = "–û–®–ò–ë–ö–ê"
    return image, predicted_pose, label, score

# --- 4. –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –†–ï–ñ–ò–ú–ê –ö–ê–ú–ï–†–´ ---
# (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
def camera_mode():
    # ... (–≤–µ—Å—å –∫–æ–¥ camera_mode –∏–∑ –≤–µ—Ä—Å–∏–∏ 4.3 –æ—Å—Ç–∞–µ—Ç—Å—è –∑–¥–µ—Å—å) ...
    st.subheader("–†–µ–∂–∏–º: –û–Ω–ª–∞–π–Ω (–ö–∞–º–µ—Ä–∞)")
    camera_action = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", ('–ü–æ–∫–∞–∑–∞—Ç—å –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã', '–°–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Å —Ç–∞–π–º–µ—Ä–æ–º'))
    if camera_action == '–ü–æ–∫–∞–∑–∞—Ç—å –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã':
        st.write("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É.")
        run_camera = st.button("–í–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É"); st_frame = st.empty()
        if run_camera:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened(): st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ."); return
            stop_button_placeholder = st.empty(); stop_button_pressed = stop_button_placeholder.button("‚èπÔ∏è –í—ã–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É", key="stop_cam")
            while cap.isOpened() and not stop_button_pressed:
                ret, frame = cap.read();
                if not ret: break
                frame = cv2.flip(frame, 1); st_frame.image(frame, channels="BGR", use_container_width=True)
                stop_button_pressed = stop_button_placeholder.button("‚èπÔ∏è –í—ã–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É", key="stop_cam")
            cap.release(); st_frame.empty(); stop_button_placeholder.empty(); st.info("–ö–∞–º–µ—Ä–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞.")
    elif camera_action == '–°–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Å —Ç–∞–π–º–µ—Ä–æ–º':
        st.write("–í—ã–±–µ—Ä–∏—Ç–µ –≤—Ä–µ–º—è —Ç–∞–π–º–µ—Ä–∞, –≤—Å—Ç–∞–Ω—å—Ç–µ –≤ –ø–æ–∑—É –∏ –Ω–∞–∂–º–∏—Ç–µ '–°—Ç–∞—Ä—Ç'.")
        timer_duration = st.selectbox("–í—Ä–µ–º—è —Ç–∞–π–º–µ—Ä–∞ (—Å–µ–∫—É–Ω–¥—ã):", [3, 5, 10])
        start_button = st.button(f"üì∏ –°—Ç–∞—Ä—Ç ({timer_duration} —Å–µ–∫)"); st_frame = st.empty(); result_placeholder = st.empty()
        if start_button:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened(): st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ."); return
            start_time = time.time(); snapshot = None
            while cap.isOpened():
                ret, frame = cap.read();
                if not ret: break
                frame = cv2.flip(frame, 1); elapsed_time = time.time() - start_time; remaining_time = timer_duration - elapsed_time
                if remaining_time > 0:
                    timer_text = str(int(np.ceil(remaining_time)))
                    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)); draw = ImageDraw.Draw(pil_image)
                    text_width, text_height = draw.textbbox((0,0), timer_text, font=font_timer)[2:]
                    text_x = (frame.shape[1] - text_width) // 2; text_y = (frame.shape[0] - text_height) // 2
                    draw.text((text_x+5, text_y+5), timer_text, font=font_timer, fill=(0, 0, 0, 128))
                    draw.text((text_x, text_y), timer_text, font=font_timer, fill=(255, 0, 0))
                    frame_with_timer = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
                    st_frame.image(frame_with_timer, channels="BGR", use_container_width=True); time.sleep(0.03)
                else: snapshot = frame.copy(); break
            cap.release(); st_frame.empty()
            if snapshot is not None:
                st.info("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–Ω–∏–º–æ–∫..."); analyzed_image, pose_name, pose_label, score = analyze_snapshot(snapshot)
                st.image(analyzed_image, channels="BGR", caption="–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å–Ω–∏–º–∫–∞", use_container_width=True)
                if pose_name != "error":
                    if score > 0: result_placeholder.success(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –ø–æ–∑–∞: **{pose_label}** (+{score} –±–∞–ª–ª–æ–≤)")
                    else: result_placeholder.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –ø–æ–∑–∞: **{pose_label}** (0 –±–∞–ª–ª–æ–≤)")

# --- 5. –ò–ù–¢–ï–†–§–ï–ô–° STREAMLIT ---
st.set_page_config(layout="wide")
st.title("ü§ñ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–∏–º–Ω–∞—Å—Ç–∏–∫–∏")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state ---
if 'manual_score' not in st.session_state: st.session_state.manual_score = 0
if 'manual_protocol' not in st.session_state: st.session_state.manual_protocol = []
# –ù–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ñ–æ—Ç–æ
if 'photo_analyzed' not in st.session_state: st.session_state.photo_analyzed = False
if 'correction_made' not in st.session_state: st.session_state.correction_made = False

# --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å: –í–´–ë–û–† –†–ï–ñ–ò–ú–ê + –ù–ê–°–¢–†–û–ô–ö–ê COOLDOWN ---
st.sidebar.title("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
analysis_mode = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
    ('–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (–ò–ò)', '–†—É—á–Ω–æ–π', '–û–Ω–ª–∞–π–Ω (–ö–∞–º–µ—Ä–∞)', '–ê–Ω–∞–ª–∏–∑ –§–æ—Ç–æ'),
    key='mode_select', # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á, —á—Ç–æ–±—ã —Å–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ —Å–º–µ–Ω–µ —Ä–µ–∂–∏–º–∞
    on_change=lambda: st.session_state.update(photo_analyzed=False, correction_made=False) # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ —Ñ–æ—Ç–æ
)

cooldown_frames = 30
if analysis_mode == '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (–ò–ò)':
     cooldown_frames = st.sidebar.slider(
         "'–ü–µ—Ä–∏–æ–¥ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è' –ò–ò (–∫–∞–¥—Ä—ã):", min_value=5, max_value=90, value=30,
         help="–°–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –ò–ò –¥–æ–ª–∂–µ–Ω '–º–æ–ª—á–∞—Ç—å' –ø–æ—Å–ª–µ –∑–∞—Å—á–∏—Ç—ã–≤–∞–Ω–∏—è —Ç—Ä—é–∫–∞ (30 –∫–∞–¥—Ä–æ–≤ ‚âà 1 —Å–µ–∫)."
     )

settings = { "cooldown_frames": cooldown_frames }

# --- –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å ---

if analysis_mode == '–û–Ω–ª–∞–π–Ω (–ö–∞–º–µ—Ä–∞)':
    camera_mode()

elif analysis_mode == '–ê–Ω–∞–ª–∏–∑ –§–æ—Ç–æ':
    st.subheader("–†–µ–∂–∏–º: –ê–Ω–∞–ª–∏–∑ –§–æ—Ç–æ")
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ —Ñ–æ—Ç–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∑—ã.")
    uploaded_image = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ç–æ",
        type=['png', 'jpg', 'jpeg'],
        key='photo_uploader', # –ö–ª—é—á –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞
        on_change=lambda: st.session_state.update(photo_analyzed=False, correction_made=False) # –°–±—Ä–æ—Å –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ç–æ
    )

    if uploaded_image is not None:
        image_bytes = uploaded_image.read()
        nparr = np.frombuffer(image_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if frame is not None:
            # --- –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–æ—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ---
            if not st.session_state.photo_analyzed:
                st.info("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–æ—Ç–æ...")
                analyzed_image, pose_name, pose_label, score = analyze_snapshot(frame)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ session_state
                st.session_state.analyzed_image = analyzed_image
                st.session_state.predicted_pose = pose_name
                st.session_state.predicted_label = pose_label
                st.session_state.predicted_score = score
                st.session_state.photo_analyzed = True # –°—Ç–∞–≤–∏–º —Ñ–ª–∞–≥, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ —Å–¥–µ–ª–∞–Ω
                st.session_state.correction_made = False # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
                st.rerun() # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç, —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–∏—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

            # --- –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–≤—Å–µ–≥–¥–∞, –µ—Å–ª–∏ —Ñ–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ) ---
            col1, col2 = st.columns(2)
            with col1:
                st.image(uploaded_image, caption="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ", use_container_width=True)
            with col2:
                # –ë–µ—Ä–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ session_state
                if 'analyzed_image' in st.session_state:
                     st.image(st.session_state.analyzed_image, channels="BGR", caption="–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞", use_container_width=True)

            # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if 'predicted_pose' in st.session_state:
                pose_name = st.session_state.predicted_pose
                pose_label = st.session_state.predicted_label
                score = st.session_state.predicted_score

                if pose_name != "error":
                    st.write(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ò–ò:** {pose_label} ({score} –±–∞–ª–ª–æ–≤)")

                    # --- –ù–û–í–´–ô –ë–õ–û–ö: –ö–ù–û–ü–ö–ò –ö–û–†–†–ï–ö–¶–ò–ò ---
                    st.write("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–Ω–æ–µ?")
                    col_corr1, col_corr2, col_corr3 = st.columns([1,1,3]) # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–Ω–æ–ø–æ–∫

                    with col_corr1:
                        if st.button("üëç –ü—Ä–∞–≤–∏–ª—å–Ω–æ", key="correct_yes", disabled=st.session_state.correction_made):
                            st.session_state.correction_made = True
                            st.success("–û—Ç–ª–∏—á–Ω–æ! –°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ.")
                            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–¥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è '–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ' –ø—Ä–∏–º–µ—Ä–∞ (–ø–æ–∫–∞ –Ω–µ –¥–µ–ª–∞–µ–º)
                            st.rerun() # –û–±–Ω–æ–≤–ª—è–µ–º, —á—Ç–æ–±—ã –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∫–Ω–æ–ø–∫–∏

                    with col_corr2:
                         # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ" —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—â–µ –Ω–µ –±—ã–ª–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
                        if st.button("üëé –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ", key="correct_no", disabled=st.session_state.correction_made):
                            st.session_state.correction_made = True # –°—Ç–∞–≤–∏–º —Ñ–ª–∞–≥, —á—Ç–æ –Ω–∞—á–∞–ª–∞—Å—å –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
                            # –ù–µ –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ä–∞–∑—É, –∂–¥–µ–º –≤—ã–±–æ—Ä–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ–∑—ã
                            st.rerun() # –û–±–Ω–æ–≤–ª—è–µ–º, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å selectbox

                    # --- –í—ã–±–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ–∑—ã (–ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ") ---
                    if st.session_state.correction_made and 'predicted_pose' in st.session_state and st.session_state.predicted_pose != "error":
                         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ "–ü—Ä–∞–≤–∏–ª—å–Ω–æ", —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å selectbox –∑—Ä—è
                         if not st.session_state.get('correct_yes_pressed', False): # –ò—Å–ø–æ–ª—å–∑—É–µ–º get –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
                              # –ò—â–µ–º –∏–Ω–¥–µ–∫—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–∑—ã –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                              try:
                                   default_index = POSE_OPTIONS.index(st.session_state.predicted_pose)
                              except ValueError:
                                   default_index = 0 # –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–∑—ã –Ω–µ—Ç –≤ –æ–ø—Ü–∏—è—Ö (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ)

                              correct_pose = st.selectbox(
                                   "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ–∑—É:",
                                   options=POSE_OPTIONS,
                                   format_func=lambda x: POSE_NAMES_RU[x], # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                                   index=default_index, # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–∑—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                                   key='correct_pose_select'
                              )
                              if st.button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", key="confirm_correction"):
                                   st.info(f"–°–ø–∞—Å–∏–±–æ! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∞–Ω–æ: {POSE_NAMES_RU[correct_pose]}")
                                   # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–¥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ' –ø—Ä–∏–º–µ—Ä–∞ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                                   # –ù–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–ø–∏—Å–∞—Ç—å –≤ —Ñ–∞–π–ª: f"{uploaded_image.name},{st.session_state.predicted_pose},{correct_pose}"

                else:
                    st.error("–í–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.")
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")


else: # –†–µ–∂–∏–º—ã –ê–≤—Ç–æ(–ò–ò) –∏ –†—É—á–Ω–æ–π
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–µ–º.")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ-—Ñ–∞–π–ª", type=["mp4", "mov", "avi"])

    if uploaded_file is not None:
        video_bytes = uploaded_file.read()
        st.video(video_bytes)

        if analysis_mode == '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (–ò–ò)':
            # ... (–∫–æ–¥ –¥–ª—è –ê–≤—Ç–æ –ò–ò –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
             st.subheader("–†–µ–∂–∏–º: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (–ò–ò)")
             if st.button("–ù–∞—á–∞—Ç—å –ò–ò-–∞–Ω–∞–ª–∏–∑"):
                 st.info("–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ò–ò... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.")
                 ai_total_score, ai_protocol_entries = process_video_ai(video_bytes, settings)
                 st.subheader("üìù –î–µ—Ç–∞–ª—å–Ω—ã–π –ü—Ä–æ—Ç–æ–∫–æ–ª (–ò–ò)")
                 if not ai_protocol_entries: st.warning("–ò–ò –Ω–µ –∑–∞—Å—á–∏—Ç–∞–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç—Ä—é–∫–∞.")
                 else:
                     for entry in ai_protocol_entries: st.write(entry)
                 report_text = f"–§–ò–ù–ê–õ–¨–ù–´–ô –ü–†–û–¢–û–ö–û–õ –ê–ù–ê–õ–ò–ó–ê (–ò–ò)\n–ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {ai_total_score} –±–∞–ª–ª–æ–≤\n\n--- –î–µ—Ç–∞–ª—å–Ω—ã–π –õ–æ–≥ –¢—Ä—é–∫–æ–≤ ---\n"
                 report_text += "\n".join(ai_protocol_entries) if ai_protocol_entries else "–ù–∏ –æ–¥–Ω–æ–≥–æ —Ç—Ä—é–∫–∞ –Ω–µ –∑–∞—Å—á–∏—Ç–∞–Ω–æ."
                 report_text += f"\n\n---\n–ù–∞—Å—Ç—Ä–æ–π–∫–∏: Cooldown = {settings['cooldown_frames']} –∫–∞–¥—Ä–æ–≤"
                 st.download_button(label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª –ò–ò (.txt)",data=report_text,file_name="gymnastics_report_AI.txt",mime="text/plain")

        elif analysis_mode == '–†—É—á–Ω–æ–π':
            # ... (–∫–æ–¥ –¥–ª—è –†—É—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
            st.subheader("–†–µ–∂–∏–º: –†—É—á–Ω–æ–π")
            st.write("–°–º–æ—Ç—Ä–∏—Ç–µ –≤–∏–¥–µ–æ, —Å—Ç–∞–≤—å—Ç–µ –Ω–∞ –ø–∞—É–∑—É –∏ –Ω–∞–∂–∏–º–∞–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –±–∞–ª–ª–æ–≤.")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                if st.button("ü§∏‚Äç‚ôÄÔ∏è –®–ø–∞–≥–∞—Ç (+10)"): st.session_state.manual_score += 10; st.session_state.manual_protocol.append(f"{format_time_manual(time.time())} - –®–ü–ê–ì–ê–¢ (+10–±)"); st.rerun()
            with col2:
                if st.button("üïäÔ∏è –õ–∞—Å—Ç–æ—á–∫–∞ (+8)"): st.session_state.manual_score += 8; st.session_state.manual_protocol.append(f"{format_time_manual(time.time())} - –õ–ê–°–¢–û–ß–ö–ê (+8–±)"); st.rerun()
            with col3:
                if st.button("ü¶µ –ü–æ–¥—ä–µ–º –Ω–æ–≥–∏ (+5)"): st.session_state.manual_score += 5; st.session_state.manual_protocol.append(f"{format_time_manual(time.time())} - –ü–û–î–™–ï–ú –ù–û–ì–ò (+5–±)"); st.rerun()
            with col4:
                if st.button("üíç –ö–æ–ª–µ—á–∫–æ (+15)"): st.session_state.manual_score += 15; st.session_state.manual_protocol.append(f"{format_time_manual(time.time())} - –ö–û–õ–ï–ß–ö–û (+15–±)"); st.rerun()
            st.metric("–¢–µ–∫—É—â–∏–π –†—É—á–Ω–æ–π –°—á–µ—Ç:", st.session_state.manual_score)
            st.subheader("üìù –ü—Ä–æ—Ç–æ–∫–æ–ª –†—É—á–Ω–æ–π –û—Ü–µ–Ω–∫–∏")
            if not st.session_state.manual_protocol: st.info("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫–∏ –≤—ã—à–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä—é–∫–∏.")
            else:
                for entry in reversed(st.session_state.manual_protocol): st.write(entry)
            if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å —Ä—É—á–Ω–æ–π —Å—á–µ—Ç"): st.session_state.manual_score = 0; st.session_state.manual_protocol = []; st.rerun()
            if st.session_state.manual_protocol:
                report_text = f"–ü–†–û–¢–û–ö–û–õ –†–£–ß–ù–û–ô –û–¶–ï–ù–ö–ò\n–ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {st.session_state.manual_score} –±–∞–ª–ª–æ–≤\n\n--- –î–µ—Ç–∞–ª—å–Ω—ã–π –õ–æ–≥ –¢—Ä—é–∫–æ–≤ ---\n"
                report_text += "\n".join(st.session_state.manual_protocol)
                st.download_button(label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ä—É—á–Ω–æ–π –ø—Ä–æ—Ç–æ–∫–æ–ª (.txt)",data=report_text,file_name="gymnastics_report_manual.txt",mime="text/plain")

st.markdown("---")
st.caption("–°–æ–∑–¥–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é Streamlit, OpenCV –∏ MediaPipe")
