import streamlit as st
import tempfile
import cv2
import numpy as np
import mediapipe as mp
from PIL import ImageFont, ImageDraw, Image
import joblib # <-- Ð˜ÐœÐŸÐžÐ Ð¢ Ð”Ð›Ð¯ Ð—ÐÐ“Ð Ð£Ð—ÐšÐ˜ "ÐœÐžÐ—Ð“Ð"

# --- 1. Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð Ð•Ð¡Ð£Ð Ð¡ÐžÐ’ ---

# --- ÐŸÐ£Ð¢Ð¬ Ðš Ð¨Ð Ð˜Ð¤Ð¢Ð£ ---
FONT_PATH = 'VERDANA.TTF' 
font_trick = ImageFont.truetype(FONT_PATH, 36)
font_score = ImageFont.truetype(FONT_PATH, 30)

# --- Ð—ÐÐ“Ð Ð£Ð—ÐšÐ "ÐœÐžÐ—Ð“Ð" (Ð˜Ð˜-ÐœÐžÐ”Ð•Ð›Ð˜) ---
try:
    model = joblib.load('gymnastics_model.pkl')
except FileNotFoundError:
    st.error("ÐžÐ¨Ð˜Ð‘ÐšÐ: Ð¤Ð°Ð¹Ð» 'gymnastics_model.pkl' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½! Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð²Ñ‹ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ð»Ð¸ ÐµÐ³Ð¾ Ð½Ð° GitHub.")
    st.stop() # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ, ÐµÑÐ»Ð¸ "Ð¼Ð¾Ð·Ð³" Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½

# --- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ MediaPipe ---
mp_pose = mp.solutions.pose

def format_time(milliseconds):
    total_seconds = int(milliseconds / 1000)
    minutes = total_seconds // 60
    seconds = total_seconds % 60
    return f"{minutes:02d}:{seconds:02d}"

# --- 2. ÐÐÐ¨Ð Ð“Ð›ÐÐ’ÐÐÐ¯ Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯ ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ˜ (Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð½Ð¾Ð²Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ°) ---
def process_video(video_file, settings):
    
    # --- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ---
    FRAMES_TO_HOLD = settings["hold_frames"]
    
    # --- ÐŸÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ ---
    total_score = 0
    protocol_entries = [] 
    
    # Ð¤Ð»Ð°Ð³Ð¸ Ð¸ ÑÑ‡ÐµÑ‚Ñ‡Ð¸ÐºÐ¸ ÐºÐ°Ð´Ñ€Ð¾Ð² (ÐºÐ°Ðº Ñ€Ð°Ð½ÑŒÑˆÐµ)
    current_pose = "other"
    previous_pose = "other"
    pose_hold_frames = 0
    
    # ÐžÑ‡ÐºÐ¸ Ð·Ð° Ñ‚Ñ€ÑŽÐºÐ¸ (Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð² Ð¾Ð´Ð½Ð¾Ð¼ Ð¼ÐµÑÑ‚Ðµ)
    SCORES = {
        "arabesque": 8,
        "leg_lift": 5,
        "split": 10,
        "other": 0
    }
    
    # ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ñ Ñ‚Ñ€ÑŽÐºÐ¾Ð² Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼
    POSE_NAMES_RU = {
        "arabesque": "Ð›ÐÐ¡Ð¢ÐžÐ§ÐšÐ",
        "leg_lift": "ÐŸÐžÐ”ÐªÐ•Ðœ ÐÐžÐ“Ð˜",
        "split": "Ð¨ÐŸÐÐ“ÐÐ¢",
        "other": ""
    }
    
    cap = cv2.VideoCapture(video_file)
    
    # Ð˜Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    current_frame = 0
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    st_frame = st.empty()

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€
            current_frame += 1
            progress_percent = int((current_frame / total_frames) * 100)
            progress_text.text(f"Ð˜Ð´ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°... ÐšÐ°Ð´Ñ€ {current_frame}/{total_frames} ({progress_percent}%)")
            progress_bar.progress(progress_percent)
            
            current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)
            current_time_str = format_time(current_time_msec)
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            trick_text = ""

            try:
                landmarks = results.pose_landmarks.landmark
                
                # --- 1. ÐŸÐ Ð•Ð’Ð ÐÐ©ÐÐ•Ðœ Ð¡ÐšÐ•Ð›Ð•Ð¢ Ð’ "ÐžÐ¢ÐŸÐ•Ð§ÐÐ¢ÐžÐš" ---
                # (Ð¢Ð¾Ñ‡Ð½Ð¾ Ñ‚Ð°Ðº Ð¶Ðµ, ÐºÐ°Ðº Ð² train_model.py)
                pose_landmarks_list = []
                for landmark in landmarks:
                    pose_landmarks_list.extend([landmark.x, landmark.y, landmark.z])

                # --- 2. "ÐœÐžÐ—Ð“" Ð”Ð•Ð›ÐÐ•Ð¢ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð• ---
                # ÐœÑ‹ "ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼" Ð˜Ð˜: "ÐÐ° Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ñ…Ð¾Ð¶Ð° ÑÑ‚Ð° Ð¿Ð¾Ð·Ð°?"
                # model.predict() Ð¾Ð¶Ð¸Ð´Ð°ÐµÑ‚ 2D-Ð¼Ð°ÑÑÐ¸Ð², Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ [pose_landmarks_list]
                prediction = model.predict([pose_landmarks_list])
                current_pose = prediction[0] # (Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ñ‚.Ðº. Ð¾Ð½ Ð¾Ð´Ð¸Ð½)
                
                # --- 3. Ð›ÐžÐ“Ð˜ÐšÐ ÐžÐ¦Ð•ÐÐšÐ˜ (Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ) ---
                
                if current_pose != "other":
                    # Ð•ÑÐ»Ð¸ Ð˜Ð˜ ÑƒÐ²Ð¸Ð´ÐµÐ» Ñ‚Ñ€ÑŽÐº
                    
                    if current_pose == previous_pose:
                        # ÐœÑ‹ Ð²ÑÐµ ÐµÑ‰Ðµ Ð² Ñ‚Ð¾Ð¹ Ð¶Ðµ Ð¿Ð¾Ð·Ðµ, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ ÐºÐ°Ð´Ñ€Ñ‹
                        pose_hold_frames += 1
                        
                        trick_text = f"{POSE_NAMES_RU[current_pose]}! (Ð”ÐµÑ€Ð¶Ð°Ñ‚ÑŒ... {pose_hold_frames}/{FRAMES_TO_HOLD})"
                        
                        if pose_hold_frames == FRAMES_TO_HOLD:
                            # Ð£Ñ€Ð°! ÐœÑ‹ Ð¿Ñ€Ð¾Ð´ÐµÑ€Ð¶Ð°Ð»Ð¸ Ð¿Ð¾Ð·Ñƒ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð´Ð¾Ð»Ð³Ð¾!
                            score = SCORES[current_pose]
                            label = POSE_NAMES_RU[current_pose]
                            
                            total_score += score
                            trick_text = f"{label}! +{score} Ð‘ÐÐ›Ð›ÐžÐ’"
                            protocol_entries.append(f"{current_time_str} - {label} (+{score}Ð±)")
                    else:
                        # Ð­Ñ‚Ð¾ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ‚Ñ€ÑŽÐº, ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÑ‡ÐµÑ‚Ñ‡Ð¸Ðº
                        pose_hold_frames = 1
                        previous_pose = current_pose
                else:
                    # Ð•ÑÐ»Ð¸ Ð˜Ð˜ ÑƒÐ²Ð¸Ð´ÐµÐ» "other", ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ
                    pose_hold_frames = 0
                    previous_pose = "other"
                    
            except Exception as e:
                # Ð•ÑÐ»Ð¸ "ÑÐºÐµÐ»ÐµÑ‚" Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼
                pose_hold_frames = 0
                previous_pose = "other"
                pass 
            
            # --- ÐžÑ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ° ---
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_image)
            
            if trick_text:
                draw.text((50, 50), trick_text, font=font_trick, fill=(0, 255, 0))
            draw.text((50, 100), f"Ð’Ð Ð•ÐœÐ¯: {current_time_str} | Ð˜Ð¢ÐžÐ“Ðž Ð‘ÐÐ›Ð›ÐžÐ’: {total_score}", font=font_score, fill=(255, 255, 0))
            
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR) 
            st_frame.image(image, channels="BGR", use_container_width=True)

        cap.release()
        
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€
        progress_text.empty()
        progress_bar.empty()
        
        # --- Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ ---
        st.success(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°! Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ ÑÑ‡ÐµÑ‚: {total_score} Ð±Ð°Ð»Ð»Ð¾Ð².")
        st.balloons() 
        
        st.subheader("ðŸ“ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐŸÑ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» (Ð›Ð¾Ð³)")
        
        if not protocol_entries:
            st.warning("ÐÐ¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÑŽÐºÐ° Ð½Ðµ Ð·Ð°ÑÑ‡Ð¸Ñ‚Ð°Ð½Ð¾.")
        else:
            for entry in protocol_entries:
                st.write(entry)
        
        # --- ÐšÐÐžÐŸÐšÐ Ð¡ÐšÐÐ§Ð˜Ð’ÐÐÐ˜Ð¯ ---
        report_text = f"""
        ==================================
        Ð¤Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ ÐŸÐ ÐžÐ¢ÐžÐšÐžÐ› ÐÐÐÐ›Ð˜Ð—Ð (Ð˜Ð˜-ÐœÐžÐ”Ð•Ð›Ð¬)
        ==================================
        
        Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ ÑÑ‡ÐµÑ‚: {total_score} Ð±Ð°Ð»Ð»Ð¾Ð²
        
        --- Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð›Ð¾Ð³ Ð¢Ñ€ÑŽÐºÐ¾Ð² ---
        """
        if not protocol_entries:
            report_text += "\nÐÐ¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÑŽÐºÐ° Ð½Ðµ Ð·Ð°ÑÑ‡Ð¸Ñ‚Ð°Ð½Ð¾."
        else:
            for entry in protocol_entries:
                report_text += f"\n{entry}"
        
        report_text += f"""
        
        ==================================
        --- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ---
        Ð’Ñ€ÐµÐ¼Ñ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ:   {settings["hold_frames"]} ÐºÐ°Ð´Ñ€Ð¾Ð²
        """
        
        st.download_button(
            label="â¬‡ï¸ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» (.txt)",
            data=report_text,
            file_name="gymnastics_report_AI.txt",
            mime="text/plain"
        )

# --- 3. ÐšÐžÐ” "Ð¡ÐÐ™Ð¢Ð" (Streamlit) ---
st.set_page_config(layout="wide")
st.title("ðŸ¤– Ð˜Ð˜-ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ…ÑƒÐ´Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð¹ Ð³Ð¸Ð¼Ð½Ð°ÑÑ‚Ð¸ÐºÐ¸")

st.sidebar.title("ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¡ÑƒÐ´ÑŒÐ¸")
st.sidebar.write("ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")

# (ÐœÑ‹ ÑƒÐ±Ñ€Ð°Ð»Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¿Ð¾Ð»Ð·ÑƒÐ½ÐºÐ¸ Ð´Ð»Ñ ÑƒÐ³Ð»Ð¾Ð², Ñ‚.Ðº. Ð˜Ð˜ Ð¾Ð½Ð¸ Ð½Ðµ Ð½ÑƒÐ¶Ð½Ñ‹)
hold_frames = st.sidebar.slider(
    "Ð’Ñ€ÐµÐ¼Ñ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð·Ñ‹ (ÐºÐ°Ð´Ñ€Ñ‹):", 
    min_value=5, max_value=60, value=10
)

# Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
settings = {
    "hold_frames": hold_frames,
}

st.write("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð²Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸ÐµÐ¼, Ð¸ Ð˜Ð˜-Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¾Ñ†ÐµÐ½Ð¸Ñ‚ Ñ‚Ñ€ÑŽÐºÐ¸.")

uploaded_file = st.file_uploader("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾-Ñ„Ð°Ð¹Ð»", type=["mp4", "mov", "avi"])

if uploaded_file is not None:
    st.video(uploaded_file)
    
    if st.button("ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·"):
        st.info("Ð˜Ð´ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°... Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ.")
        process_video(uploaded_file.read(), settings)
