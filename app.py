import streamlit as st
import tempfile
import cv2
import numpy as np
import mediapipe as mp
from PIL import ImageFont, ImageDraw, Image
import joblib 

# --- 1. –ó–ê–ì–†–£–ó–ö–ê –†–ï–°–£–†–°–û–í ---

# --- –ü–£–¢–¨ –ö –®–†–ò–§–¢–£ ---
FONT_PATH = 'VERDANA.TTF' 
font_trick = ImageFont.truetype(FONT_PATH, 36)
font_score = ImageFont.truetype(FONT_PATH, 30)

# --- –ó–ê–ì–†–£–ó–ö–ê "–ú–û–ó–ì–ê" (–ò–ò-–ú–û–î–ï–õ–ò) ---
try:
    model = joblib.load('gymnastics_model.pkl')
except FileNotFoundError:
    st.error("–û–®–ò–ë–ö–ê: –§–∞–π–ª 'gymnastics_model.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –µ–≥–æ –Ω–∞ GitHub.")
    st.stop() 

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe ---
mp_pose = mp.solutions.pose

def format_time(milliseconds):
    total_seconds = int(milliseconds / 1000)
    minutes = total_seconds // 60
    seconds = total_seconds % 60
    return f"{minutes:02d}:{seconds:02d}"

# --- 2. –ù–ê–®–ê –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò ---
def process_video(video_file): 
    
    # --- –ù–û–í–´–ô –ë–õ–û–ö: "–ü–ï–†–ò–û–î –û–•–õ–ê–ñ–î–ï–ù–ò–Ø" ---
    # –ù–µ –Ω–∞—á–∏—Å–ª—è—Ç—å –±–∞–ª–ª—ã –≤ —Ç–µ—á–µ–Ω–∏–µ N –∫–∞–¥—Ä–æ–≤ –ø–æ—Å–ª–µ —Ç—Ä—é–∫–∞
    COOLDOWN_FRAMES = 30 # (30 –∫–∞–¥—Ä–æ–≤ = ~1 —Å–µ–∫—É–Ω–¥–∞)
    frames_since_last_score = COOLDOWN_FRAMES # (–ù–∞—á–∏–Ω–∞–µ–º —Å > 30, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ —Å—Ä–∞–∑—É –∑–∞—Å—á–∏—Ç–∞—Ç—å)
    # --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ë–õ–û–ö–ê ---
    
    # --- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
    total_score = 0
    protocol_entries = [] 

    # –û—á–∫–∏ –∑–∞ —Ç—Ä—é–∫–∏
    SCORES = {
        "arabesque": 8,
        "leg_lift": 5,
        "split": 10,
        "other": 0
    }
    
    # –ù–∞–∑–≤–∞–Ω–∏—è —Ç—Ä—é–∫–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    POSE_NAMES_RU = {
        "arabesque": "–õ–ê–°–¢–û–ß–ö–ê",
        "leg_lift": "–ü–û–î–™–ï–ú –ù–û–ì–ò",
        "split": "–®–ü–ê–ì–ê–¢",
        "other": ""
    }
    
    # --- –ß–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ –±–∞–π—Ç–æ–≤ ---
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(video_file)
    video_path = tfile.name
    
    cap = cv2.VideoCapture(video_path)
    
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    current_frame = 0
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    st_frame = st.empty()

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # --- –û–ë–ù–û–í–õ–ï–ù–û: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ "–æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è" ---
            frames_since_last_score += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
            current_frame += 1
            if total_frames > 0:
                progress_percent = int((current_frame / total_frames) * 100)
            else:
                progress_percent = 0
            progress_text.text(f"–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞... –ö–∞–¥—Ä {current_frame}/{total_frames} ({progress_percent}%)")
            progress_bar.progress(progress_percent)
            
            current_time_msec = cap.get(cv2.CAP_PROP_POS_MSEC)
            current_time_str = format_time(current_time_msec)
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            trick_text = ""
            current_pose = "other"

            try:
                landmarks = results.pose_landmarks.landmark
                
                pose_landmarks_list = []
                for landmark in landmarks:
                    pose_landmarks_list.extend([landmark.x, landmark.y, landmark.z])

                prediction = model.predict([pose_landmarks_list])
                current_pose = prediction[0] 
                
                # --- –û–ë–ù–û–í–õ–ï–ù–û: –õ–û–ì–ò–ö–ê –û–¶–ï–ù–ö–ò (–° "–û–•–õ–ê–ñ–î–ï–ù–ò–ï–ú") ---
                
                if current_pose != "other":
                    # –ï—Å–ª–∏ –ò–ò —É–≤–∏–¥–µ–ª —Ç—Ä—é–∫
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ "–æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ"
                    if frames_since_last_score > COOLDOWN_FRAMES:
                        score = SCORES[current_pose]
                        label = POSE_NAMES_RU[current_pose]
                        
                        total_score += score
                        trick_text = f"{label}! +{score} –ë–ê–õ–õ–û–í"
                        protocol_entries.append(f"{current_time_str} - {label} (+{score}–±)")
                        
                        # –°–ë–†–ê–°–´–í–ê–ï–ú –°–ß–ï–¢–ß–ò–ö
                        frames_since_last_score = 0 
                # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–ô ---
                    
            except Exception as e:
                pass 
            
            # --- –û—Ç—Ä–∏—Å–æ–≤–∫–∞ ---
            mp.solutions.drawing_utils.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_image)
            
            if trick_text:
                draw.text((50, 50), trick_text, font=font_trick, fill=(0, 255, 0))
            draw.text((50, 100), f"–í–†–ï–ú–Ø: {current_time_str} | –ò–¢–û–ì–û –ë–ê–õ–õ–û–í: {total_score}", font=font_score, fill=(255, 255, 0))
            
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR) 
            st_frame.image(image, channels="BGR", use_container_width=True)

        cap.release()
        
        # –û—á–∏—â–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
        progress_text.empty()
        progress_bar.empty()
        
        # --- –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç ---
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {total_score} –±–∞–ª–ª–æ–≤.")
        st.balloons() 
        
        st.subheader("üìù –î–µ—Ç–∞–ª—å–Ω—ã–π –ü—Ä–æ—Ç–æ–∫–æ–ª (–õ–æ–≥)")
        
        if not protocol_entries:
            st.warning("–ù–∏ –æ–¥–Ω–æ–≥–æ —Ç—Ä—é–∫–∞ –Ω–µ –∑–∞—Å—á–∏—Ç–∞–Ω–æ.")
        else:
            for entry in protocol_entries:
                st.write(entry)
        
        # --- –ö–ù–û–ü–ö–ê –°–ö–ê–ß–ò–í–ê–ù–ò–Ø ---
        report_text = f"""
        ==================================
        –§–ò–ù–ê–õ–¨–ù–´–ô –ü–†–û–¢–û–ö–û–õ –ê–ù–ê–õ–ò–ó–ê (–ò–ò-–ú–û–î–ï–õ–¨ v3)
        ==================================
        
        –ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç: {total_score} –±–∞–ª–ª–æ–≤
        
        --- –î–µ—Ç–∞–ª—å–Ω—ã–π –õ–æ–≥ –¢—Ä—é–∫–æ–≤ ---
        """
        if not protocol_entries:
            report_text += "\n–ù–∏ –æ–¥–Ω–æ–≥–æ —Ç—Ä—é–∫–∞ –Ω–µ –∑–∞—Å—á–∏—Ç–∞–Ω–æ."
        else:
            for entry in protocol_entries:
                report_text += f"\n{entry}"
        
        report_text += f"""
        
        ==================================
        """
        
        st.download_button(
            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª (.txt)",
            data=report_text,
            file_name="gymnastics_report_AI_v3.txt",
            mime="text/plain"
        )

# --- 3. –ö–û–î "–°–ê–ô–¢–ê" (Streamlit) ---
st.set_page_config(layout="wide")
st.title("ü§ñ –ò–ò-–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–∏–º–Ω–∞—Å—Ç–∏–∫–∏")

st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–µ–º, –∏ –ò–ò-–º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏—Ç —Ç—Ä—é–∫–∏.")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ-—Ñ–∞–π–ª", type=["mp4", "mov", "avi"])

if uploaded_file is not None:
    st.video(uploaded_file)
    
    if st.button("–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑"):
        st.info("–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.")
        process_video(uploaded_file.read())
